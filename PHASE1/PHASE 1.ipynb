{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define dataset file paths\n",
    "datasets = {\n",
    "    \"gas_price\": \"gas_price.csv\",\n",
    "    \"rig_count\": \"rig_count.csv\",\n",
    "    \"tam\": \"tam.csv\",\n",
    "    \"capex\": \"capex.csv\",\n",
    "    \"oil_price\": \"oil_price.csv\",\n",
    "    \"education\": \"education.csv\",\n",
    "    \"political_stability\": \"political_stability.csv\",\n",
    "    \"infrastructure_index\": \"infrastructure_index.csv\",\n",
    "    \"health_index\": \"health_index.csv\",\n",
    "    \"gni\": \"gni.xlsx\",\n",
    "    \"gdp\": \"gdp.xlsx\",\n",
    "    \"population\": \"population.xlsx\",\n",
    "    \"country_mapping\": \"country_table(in).csv\"\n",
    "}\n",
    "\n",
    "def load_data(dataset_name):\n",
    "    \"\"\"Loads and processes the dataset.\"\"\"\n",
    "    path = datasets.get(dataset_name)\n",
    "    if not path:\n",
    "        print(f\"Dataset '{dataset_name}' not found in provided paths.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if path.lower().endswith('.csv'):\n",
    "            df = pd.read_csv(path)\n",
    "        elif path.lower().endswith(('.xlsx', '.xls')):\n",
    "            df = pd.read_excel(path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format for dataset '{dataset_name}'.\")\n",
    "            return None\n",
    "\n",
    "        df[\"country_name\"] = df[\"country_name\"].str.strip().str.upper()\n",
    "        df[\"year\"] = df[\"year\"].astype(int)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ---------- Model Building ----------\n",
    "def build_nn_model(input_dim):\n",
    "    \"\"\"Builds and returns a neural network model.\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# ---------- Training Country-Specific Models ----------\n",
    "def train_model_for_country(dataset_name, country):\n",
    "    df = load_data(dataset_name)\n",
    "    if df is None:\n",
    "        print(f\"Skipping {country}: Unable to load data for {dataset_name}.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    country_df = df[df[\"country_name\"] == country]\n",
    "    if country_df.empty:\n",
    "        print(f\"Skipping {country}: No data available for {dataset_name}.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Determine target feature: first column not in country_name/year\n",
    "    target_feature = [col for col in country_df.columns if col not in [\"country_name\", \"year\"]][0]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    country_df_sorted = country_df.sort_values(\"year\")\n",
    "    country_df_sorted.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "    X = country_df_sorted.drop(columns=[\"country_name\", \"year\"])\n",
    "    y = country_df_sorted[[target_feature]]\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "    if len(X_scaled) < 5:\n",
    "        print(f\"Skipping {country}: Not enough data for training in {dataset_name}.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "    model = build_nn_model(input_dim=X_train.shape[1])\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[lr_scheduler, early_stopping],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    return model, scaler, country_df_sorted, target_feature\n",
    "\n",
    "# ---------- Training Year-Based Models ----------\n",
    "def train_nn_model(df, target_feature):\n",
    "    grouped_df = df.groupby(\"year\").mean(numeric_only=True).reset_index()\n",
    "    X = grouped_df[[\"year\"]].values\n",
    "    y = grouped_df[[target_feature]].values\n",
    "\n",
    "    scaler_X, scaler_y = MinMaxScaler(), MinMaxScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "    model = build_nn_model(input_dim=1)\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[lr_scheduler, early_stopping],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    return model, scaler_X, scaler_y\n",
    "\n",
    "# ---------- Prediction Functions ----------\n",
    "def predict_future_by_country(model, scaler, df, target_feature, start_year, num_years, country):\n",
    "    if model is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    future_predictions = []\n",
    "    latest_data = df[df[\"year\"] == df[\"year\"].max()]\n",
    "    latest_scaled = scaler.transform(\n",
    "        latest_data.drop(columns=[\"country_name\", \"year\"]))\n",
    "\n",
    "    for i in range(num_years):\n",
    "        predicted_scaled = model.predict(latest_scaled, verbose=0)\n",
    "        predicted_value = scaler.inverse_transform(predicted_scaled)[0][0]\n",
    "        trend_factor = np.random.uniform(0.9, 1.1)\n",
    "        predicted_value *= trend_factor\n",
    "\n",
    "        if target_feature == \"rig_count\":\n",
    "            predicted_value = int(round(predicted_value))\n",
    "\n",
    "        prediction_year = start_year + i\n",
    "        future_predictions.append({\n",
    "            \"year\": prediction_year,\n",
    "            \"country_name\": country,\n",
    "            target_feature: predicted_value\n",
    "        })\n",
    "        print(f\"Predicted {target_feature} for {country} in {prediction_year}: {predicted_value}\")\n",
    "\n",
    "    return pd.DataFrame(future_predictions)\n",
    "\n",
    "def predict_prices(model, scaler_X, scaler_y, start, end, countries, feature_name):\n",
    "    predictions = []\n",
    "    years = np.arange(start, end + 1).reshape(-1, 1)\n",
    "    years_scaled = scaler_X.transform(years)\n",
    "    preds_scaled = model.predict(years_scaled, verbose=0)\n",
    "    preds = scaler_y.inverse_transform(preds_scaled)\n",
    "\n",
    "    for country in countries:\n",
    "        for year, price in zip(years.flatten(), preds.flatten()):\n",
    "            predictions.append({\n",
    "                \"year\": year,\n",
    "                \"country_name\": country,\n",
    "                feature_name: price\n",
    "            })\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# --------------------------------- Main Execution Flow -------------------------------------\n",
    "valid_datasets = {\"gas_price\", \"oil_price\", \"rig_count\", \"tam\", \"capex\"}\n",
    "dataset_names_input = input(\n",
    "    \"\\nEnter what you want to predict (gas_price, oil_price, rig_count, tam, capex): \")\n",
    "dataset_names = [\n",
    "    name.strip() for name in dataset_names_input.split(',')\n",
    "    if name.strip() in valid_datasets\n",
    "]\n",
    "\n",
    "for i, name in enumerate(datasets.keys(), start=1):\n",
    "    print(f\"{i}. {name}\")\n",
    "\n",
    "print(\"\\n1. Gas Price Prediction: Uses Oil Price, Rig Count, Infrastructure Index, Capex.\")\n",
    "print(\"2. Rig Count Prediction: Uses Rig Count, Infrastructure Index, Capex, Political Stability.\")\n",
    "print(\"3. Oil Price Prediction: Uses Rig Count, GDP Growth, Infrastructure Index, Capex, Political Stability.\")\n",
    "print(\"4. Tam Prediction: Uses Capex, GDP, Population, Health Index, Education, Infrastructure Index.\")\n",
    "print(\"5. Capex Prediction: Uses Oil Price, Gas Price, Rig Count, GDP Growth, Political Stability, Infrastructure Index.\")\n",
    "\n",
    "selected_options = input(\n",
    "    \"\\nEnter the numbers corresponding to the datasets you want to predict: \"\n",
    ").strip()\n",
    "\n",
    "# Load country mapping to get available countries\n",
    "gas_price_data = load_data(\"gas_price\")\n",
    "available_countries = sorted(\n",
    "    gas_price_data[\"country_name\"].unique()\n",
    ") if gas_price_data is not None else []\n",
    "print(\n",
    "    \"\\nAvailable countries: \",\n",
    "    \", \".join(available_countries) if available_countries else \"None\"\n",
    ")\n",
    "\n",
    "selected_countries_input = input(\n",
    "    \"Enter countries (comma-separated): \"\n",
    ")\n",
    "selected_countries = [\n",
    "    c.strip().upper() for c in selected_countries_input.split(',')\n",
    "    if c.strip().upper() in available_countries\n",
    "]\n",
    "\n",
    "start_year = int(input(\"Enter the start year for predictions: \"))\n",
    "end_year = int(input(\"Enter the end year for predictions: \"))\n",
    "\n",
    "# Session ID and Company ID input\n",
    "session_id = int(input(\"Enter session id: \"))\n",
    "company_id = int(input(\"Enter company id: \"))\n",
    "\n",
    "# Train global models for gas and oil prices\n",
    "oil_price_data = load_data(\"oil_price\")\n",
    "gas_model, gas_scaler_X, gas_scaler_y = train_nn_model(\n",
    "    gas_price_data, \"gas_price\"\n",
    ")\n",
    "oil_model, oil_scaler_X, oil_scaler_y = train_nn_model(\n",
    "    oil_price_data, \"oil_price\"\n",
    ")\n",
    "\n",
    "# Create predictions skeleton\n",
    "years = list(range(start_year, end_year + 1))\n",
    "skeleton = pd.DataFrame([\n",
    "    (year, country) for country in selected_countries for year in years\n",
    "], columns=[\"year\", \"country_name\"] )\n",
    "final_predictions = skeleton.copy()\n",
    "\n",
    "# Merge dataset predictions\n",
    "for dataset in dataset_names:\n",
    "    if dataset in [\"gas_price\", \"oil_price\"]:\n",
    "        pred_df = predict_prices(\n",
    "            gas_model if dataset==\"gas_price\" else oil_model,\n",
    "            gas_scaler_X if dataset==\"gas_price\" else oil_scaler_X,\n",
    "            gas_scaler_y if dataset==\"gas_price\" else oil_scaler_y,\n",
    "            start_year, end_year, selected_countries, dataset\n",
    "        )\n",
    "        final_predictions = final_predictions.merge(\n",
    "            pred_df, on=[\"year\", \"country_name\"], how=\"left\"\n",
    "        )\n",
    "    else:\n",
    "        all_preds = []\n",
    "        for country in selected_countries:\n",
    "            model, scaler, df, target = train_model_for_country(dataset, country)\n",
    "            if model:\n",
    "                num_years = end_year - start_year + 1\n",
    "                all_preds.append(\n",
    "                    predict_future_by_country(\n",
    "                        model, scaler, df, target,\n",
    "                        start_year, num_years, country\n",
    "                    )\n",
    "                )\n",
    "        if all_preds:\n",
    "            final_predictions = final_predictions.merge(\n",
    "                pd.concat(all_preds, ignore_index=True),\n",
    "                on=[\"year\", \"country_name\"], how=\"left\"\n",
    "            )\n",
    "\n",
    "# Load and merge country mapping\n",
    "country_mapping = pd.read_csv(datasets[\"country_mapping\"])\n",
    "country_mapping[\"country_name\"] = country_mapping[\"country_name\"].str.strip().str.upper()\n",
    "final_predictions = final_predictions.merge(\n",
    "    country_mapping[[\"country_name\",\"country_id\"]],\n",
    "    on=\"country_name\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Add session_id and company_id columns\n",
    "final_predictions['session_id'] = session_id\n",
    "final_predictions['company_id'] = company_id\n",
    "\n",
    "# Reorder columns including session_id and company_id\n",
    "cols = [\n",
    "    \"session_id\",\n",
    "    \"company_id\",\n",
    "    \"country_id\",\n",
    "    \"country_name\",\n",
    "    \"year\"\n",
    "] + [col for col in final_predictions.columns if col not in {\"session_id\",\"company_id\",\"country_id\",\"country_name\",\"year\"}]\n",
    "final_predictions = final_predictions[cols]\n",
    "\n",
    "# Save predictions\n",
    "output_file = input(\n",
    "    \"\\nEnter the file name to save predictions (e.g., predictions_output.csv): \"\n",
    ").strip()\n",
    "if not output_file.lower().endswith('.csv'):\n",
    "    output_file += '.csv'\n",
    "final_predictions.to_csv(output_file, index=False)\n",
    "print(f\"\\nPredictions have been successfully saved to '{output_file}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
